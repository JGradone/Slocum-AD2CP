{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nortek AD2CP Processing Code\n",
    "##### jgradone@marine.rutgers.edu     01/11/2022    Initial\n",
    "\n",
    "This Jupyter Notebook is intended to read in AD2CP data processed to NetCDFs using the Nortek MIDAS software. The plan will eventually be to seperate a lot of these steps into different functions in a cleaned up packaged that can be published on GitHub but for now, this notebook will include most troubleshooting/processing steps here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import dirname, join as pjoin\n",
    "import glob\n",
    "import netCDF4 as nc\n",
    "import math\n",
    "import datetime\n",
    "import cartopy.crs as ccrs\n",
    "import xarray as xr\n",
    "from RU29_helpers import grid_glider\n",
    "import dbdreader\n",
    "import matplotlib.dates as mdates\n",
    "import cmocean.cm as cmo\n",
    "\n",
    "## Set some plotting formats\n",
    "plt.style.use('seaborn-poster')\n",
    "myFmtshort = mdates.DateFormatter('%m/%d\\n%H:%M')\n",
    "myFmtlong = mdates.DateFormatter('%m/%d/%y \\n%H:%M')\n",
    "myFmt = mdates.DateFormatter('%m/%d/%y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set path for where all the data lives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/joegradone/SynologyDrive/Drive/Rutgers/Research/data/Glider/RU_29/Nortek_Recovered/processed/'\n",
    "\n",
    "files = glob.glob(path+'*.nc')\n",
    "files = np.sort(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the first dataset first and then merge to subsequent ones..... someone tell me a better way to do this\n",
    "\n",
    "ds = nc.Dataset(files[0])\n",
    "\n",
    "tm                 = np.array(ds['Data']['Burst'].variables['time'])\n",
    "tm                 = pd.to_datetime(tm, unit='s').values\n",
    "pressure           = np.array(ds['Data']['Burst'].variables['Pressure'])\n",
    "heading            = np.array(ds['Data']['Burst'].variables['Heading'])\n",
    "pitch              = np.array(ds['Data']['Burst'].variables['Pitch'])\n",
    "roll               = np.array(ds['Data']['Burst'].variables['Roll'])\n",
    "bins               = np.array(ds['Data']['Burst'].variables['Velocity Range'])\n",
    "speedofsound       = np.array(ds['Data']['Burst'].variables['SpeedOfSound'])\n",
    "error              = np.array(ds['Data']['Burst'].variables['Error'])\n",
    "status             = np.array(ds['Data']['Burst'].variables['Status'])\n",
    "cellsize           = np.array(ds['Data']['Burst'].variables['CellSize'])\n",
    "numberofcells      = np.array(ds['Data']['Burst'].variables['NumberofCells'])\n",
    "blanking           = np.array(ds['Data']['Burst'].variables['Blanking'])\n",
    "nominalcorrelation = np.array(ds['Data']['Burst'].variables['NominalCorrelation'])\n",
    "ambiguity          = np.array(ds['Data']['Burst'].variables['Ambiguity'])\n",
    "ensemblecount      = np.array(ds['Data']['Burst'].variables['EnsembleCount'])\n",
    "unshiftedroll      = np.array(ds['Data']['Burst'].variables['UnshiftedRoll'])\n",
    "\n",
    "#################################\n",
    "## What to do about this.....\n",
    "#################################\n",
    "#ahrsrotationmatrix = np.array(ds['Data']['Burst'].variables['AHRSRotationMatrix'])\n",
    "\n",
    "magnetometerx = np.array(ds['Data']['Burst'].variables['MagnetometerX'])\n",
    "magnetometery = np.array(ds['Data']['Burst'].variables['MagnetometerY'])\n",
    "magnetometerz = np.array(ds['Data']['Burst'].variables['MagnetometerZ'])\n",
    "\n",
    "accelerometerx = np.array(ds['Data']['Burst'].variables['AccelerometerX'])\n",
    "accelerometery = np.array(ds['Data']['Burst'].variables['AccelerometerY'])\n",
    "accelerometerz = np.array(ds['Data']['Burst'].variables['AccelerometerZ'])\n",
    "\n",
    "beam1vel = np.array(ds['Data']['Burst'].variables['VelocityBeam1']).transpose()\n",
    "beam2vel = np.array(ds['Data']['Burst'].variables['VelocityBeam2']).transpose()\n",
    "beam3vel = np.array(ds['Data']['Burst'].variables['VelocityBeam3']).transpose()\n",
    "beam4vel = np.array(ds['Data']['Burst'].variables['VelocityBeam4']).transpose()\n",
    "\n",
    "beam1cor = np.array(ds['Data']['Burst'].variables['CorrelationBeam1']).transpose()\n",
    "beam2cor = np.array(ds['Data']['Burst'].variables['CorrelationBeam2']).transpose()\n",
    "beam3cor = np.array(ds['Data']['Burst'].variables['CorrelationBeam3']).transpose()\n",
    "beam4cor = np.array(ds['Data']['Burst'].variables['CorrelationBeam4']).transpose()\n",
    "\n",
    "beam1amp = np.array(ds['Data']['Burst'].variables['AmplitudeBeam1']).transpose()\n",
    "beam2amp = np.array(ds['Data']['Burst'].variables['AmplitudeBeam2']).transpose()\n",
    "beam3amp = np.array(ds['Data']['Burst'].variables['AmplitudeBeam3']).transpose()\n",
    "beam4amp = np.array(ds['Data']['Burst'].variables['AmplitudeBeam4']).transpose()\n",
    "\n",
    "\n",
    "\n",
    "df = xr.Dataset(\n",
    "    {\"heading\" : ((\"time\"), heading),\n",
    "     \"depth\" : ((\"time\"), pressure),\n",
    "     \"pitch\" : ((\"time\"), pitch),\n",
    "     \"roll\" : ((\"time\"), roll),\n",
    "     \"speedofsound\" : ((\"time\"), speedofsound),\n",
    "     \"error\" : ((\"time\"), error),\n",
    "     \"status\" : ((\"time\"), status),\n",
    "     \"cellsize\" : ((\"time\"), cellsize),\n",
    "     \"numberofcells\" : ((\"time\"), numberofcells),\n",
    "     \"blanking\" : ((\"time\"), blanking),\n",
    "     \"nominalcorrelation\" : ((\"time\"), nominalcorrelation),\n",
    "     \"ambiguity\" : ((\"time\"), ambiguity),\n",
    "     \"ensemblecount\" : ((\"time\"), ensemblecount),\n",
    "     \"unshiftedroll\" : ((\"time\"), unshiftedroll),\n",
    "     #\"ahrsrotationmatrix\" : ((\"time\"), ahrsrotationmatrix),\n",
    "     \n",
    "     \"magnetometerx\" : ((\"time\"), magnetometerx),\n",
    "     \"magnetometery\" : ((\"time\"), magnetometery),\n",
    "     \"magnetometerz\" : ((\"time\"), magnetometerz),\n",
    "     \"accelerometerx\" : ((\"time\"), accelerometerx),\n",
    "     \"accelerometery\" : ((\"time\"), accelerometery),\n",
    "     \"accelerometerz\" : ((\"time\"), accelerometerz),     \n",
    "     \n",
    "     \"beam1vel\" : ((\"bins\",\"time\"),beam1vel),\n",
    "     \"beam2vel\" : ((\"bins\",\"time\"),beam2vel),\n",
    "     \"beam3vel\" : ((\"bins\",\"time\"),beam3vel),\n",
    "     \"beam4vel\" : ((\"bins\",\"time\"),beam4vel),\n",
    "     \"beam1cor\" : ((\"bins\",\"time\"),beam1cor),\n",
    "     \"beam2cor\" : ((\"bins\",\"time\"),beam2cor),\n",
    "     \"beam3cor\" : ((\"bins\",\"time\"),beam3cor),\n",
    "     \"beam4cor\" : ((\"bins\",\"time\"),beam4cor),\n",
    "     \"beam1amp\" : ((\"bins\",\"time\"),beam1amp),\n",
    "     \"beam2amp\" : ((\"bins\",\"time\"),beam2amp),\n",
    "     \"beam3amp\" : ((\"bins\",\"time\"),beam3amp),\n",
    "     \"beam4amp\" : ((\"bins\",\"time\"),beam4amp)},    \n",
    "             coords   = {\"bins\":bins,\"time\":tm}\n",
    "                       )\n",
    "\n",
    "\n",
    "for x in np.arange(1,len(files)):\n",
    "    ds = nc.Dataset(files[x])\n",
    "    \n",
    "    tm                 = np.array(ds['Data']['Burst'].variables['time'])\n",
    "    tm                 = pd.to_datetime(tm, unit='s').values\n",
    "    pressure           = np.array(ds['Data']['Burst'].variables['Pressure'])\n",
    "    heading            = np.array(ds['Data']['Burst'].variables['Heading'])\n",
    "    pitch              = np.array(ds['Data']['Burst'].variables['Pitch'])\n",
    "    roll               = np.array(ds['Data']['Burst'].variables['Roll'])\n",
    "    bins               = np.array(ds['Data']['Burst'].variables['Velocity Range'])\n",
    "    speedofsound       = np.array(ds['Data']['Burst'].variables['SpeedOfSound'])\n",
    "    error              = np.array(ds['Data']['Burst'].variables['Error'])\n",
    "    status             = np.array(ds['Data']['Burst'].variables['Status'])\n",
    "    cellsize           = np.array(ds['Data']['Burst'].variables['CellSize'])\n",
    "    numberofcells      = np.array(ds['Data']['Burst'].variables['NumberofCells'])\n",
    "    blanking           = np.array(ds['Data']['Burst'].variables['Blanking'])\n",
    "    nominalcorrelation = np.array(ds['Data']['Burst'].variables['NominalCorrelation'])\n",
    "    ambiguity          = np.array(ds['Data']['Burst'].variables['Ambiguity'])\n",
    "    ensemblecount      = np.array(ds['Data']['Burst'].variables['EnsembleCount'])\n",
    "    unshiftedroll      = np.array(ds['Data']['Burst'].variables['UnshiftedRoll'])\n",
    "    #ahrsrotationmatrix = np.array(ds['Data']['Burst'].variables['AHRSRotationMatrix'])\n",
    "\n",
    "    magnetometerx = np.array(ds['Data']['Burst'].variables['MagnetometerX'])\n",
    "    magnetometery = np.array(ds['Data']['Burst'].variables['MagnetometerY'])\n",
    "    magnetometerz = np.array(ds['Data']['Burst'].variables['MagnetometerZ'])\n",
    "\n",
    "    accelerometerx = np.array(ds['Data']['Burst'].variables['AccelerometerX'])\n",
    "    accelerometery = np.array(ds['Data']['Burst'].variables['AccelerometerY'])\n",
    "    accelerometerz = np.array(ds['Data']['Burst'].variables['AccelerometerZ'])\n",
    "\n",
    "    beam1vel = np.array(ds['Data']['Burst'].variables['VelocityBeam1']).transpose()\n",
    "    beam2vel = np.array(ds['Data']['Burst'].variables['VelocityBeam2']).transpose()\n",
    "    beam3vel = np.array(ds['Data']['Burst'].variables['VelocityBeam3']).transpose()\n",
    "    beam4vel = np.array(ds['Data']['Burst'].variables['VelocityBeam4']).transpose()\n",
    "\n",
    "    beam1cor = np.array(ds['Data']['Burst'].variables['CorrelationBeam1']).transpose()\n",
    "    beam2cor = np.array(ds['Data']['Burst'].variables['CorrelationBeam2']).transpose()\n",
    "    beam3cor = np.array(ds['Data']['Burst'].variables['CorrelationBeam3']).transpose()\n",
    "    beam4cor = np.array(ds['Data']['Burst'].variables['CorrelationBeam4']).transpose()\n",
    "\n",
    "    beam1amp = np.array(ds['Data']['Burst'].variables['AmplitudeBeam1']).transpose()\n",
    "    beam2amp = np.array(ds['Data']['Burst'].variables['AmplitudeBeam2']).transpose()\n",
    "    beam3amp = np.array(ds['Data']['Burst'].variables['AmplitudeBeam3']).transpose()\n",
    "    beam4amp = np.array(ds['Data']['Burst'].variables['AmplitudeBeam4']).transpose()\n",
    "    \n",
    "    df2 = xr.Dataset(\n",
    "    {\"heading\" : ((\"time\"), heading),\n",
    "     \"depth\" : ((\"time\"), pressure),\n",
    "     \"pitch\" : ((\"time\"), pitch),\n",
    "     \"roll\" : ((\"time\"), roll),\n",
    "     \"speedofsound\" : ((\"time\"), speedofsound),\n",
    "     \"error\" : ((\"time\"), error),\n",
    "     \"status\" : ((\"time\"), status),\n",
    "     \"cellsize\" : ((\"time\"), cellsize),\n",
    "     \"numberofcells\" : ((\"time\"), numberofcells),\n",
    "     \"blanking\" : ((\"time\"), blanking),\n",
    "     \"nominalcorrelation\" : ((\"time\"), nominalcorrelation),\n",
    "     \"ambiguity\" : ((\"time\"), ambiguity),\n",
    "     \"ensemblecount\" : ((\"time\"), ensemblecount),\n",
    "     \"unshiftedroll\" : ((\"time\"), unshiftedroll),\n",
    "     #\"ahrsrotationmatrix\" : ((\"time\"), ahrsrotationmatrix),\n",
    "     \n",
    "     \"magnetometerx\" : ((\"time\"), magnetometerx),\n",
    "     \"magnetometery\" : ((\"time\"), magnetometery),\n",
    "     \"magnetometerz\" : ((\"time\"), magnetometerz),\n",
    "     \"accelerometerx\" : ((\"time\"), accelerometerx),\n",
    "     \"accelerometery\" : ((\"time\"), accelerometery),\n",
    "     \"accelerometerz\" : ((\"time\"), accelerometerz),     \n",
    "     \n",
    "     \"beam1vel\" : ((\"bins\",\"time\"),beam1vel),\n",
    "     \"beam2vel\" : ((\"bins\",\"time\"),beam2vel),\n",
    "     \"beam3vel\" : ((\"bins\",\"time\"),beam3vel),\n",
    "     \"beam4vel\" : ((\"bins\",\"time\"),beam4vel),\n",
    "     \"beam1cor\" : ((\"bins\",\"time\"),beam1cor),\n",
    "     \"beam2cor\" : ((\"bins\",\"time\"),beam2cor),\n",
    "     \"beam3cor\" : ((\"bins\",\"time\"),beam3cor),\n",
    "     \"beam4cor\" : ((\"bins\",\"time\"),beam4cor),\n",
    "     \"beam1amp\" : ((\"bins\",\"time\"),beam1amp),\n",
    "     \"beam2amp\" : ((\"bins\",\"time\"),beam2amp),\n",
    "     \"beam3amp\" : ((\"bins\",\"time\"),beam3amp),\n",
    "     \"beam4amp\" : ((\"bins\",\"time\"),beam4amp)},    \n",
    "             coords   = {\"bins\":bins,\"time\":tm}\n",
    "                       )\n",
    "    \n",
    "    df = xr.merge([df, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take a quick peak at some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x,y]=np.meshgrid(df.time,df.bins)\n",
    "[bdepth,bbins]=np.meshgrid(df.depth,df.bins)\n",
    "\n",
    "by=bdepth+bbins\n",
    "\n",
    "fig = plt.figure(figsize=(25,12))\n",
    "\n",
    "plt.pcolormesh(x[:,1326700:1328000],-by[:,1326700:1328000],df.beam1cor[:,1326700:1328000])\n",
    "plt.plot(df.time[1326700:1328000],-df.depth[1326700:1328000],'k')\n",
    "plt.colorbar(label='Beam 1 Correlation')\n",
    "plt.gca().xaxis.set_major_formatter(myFmtlong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x,y]=np.meshgrid(df.time,df.bins)\n",
    "[bdepth,bbins]=np.meshgrid(df.depth,df.bins)\n",
    "\n",
    "by=bdepth+bbins\n",
    "\n",
    "fig = plt.figure(figsize=(25,12))\n",
    "\n",
    "plt.pcolormesh(x[:,1351000:1352000],-by[:,1351000:1352000],df.beam1cor[:,1351000:1352000])\n",
    "plt.plot(df.time[1351000:1352000],-df.depth[1351000:1352000],'k')\n",
    "plt.colorbar(label='Beam 1 Correlation')\n",
    "plt.gca().xaxis.set_major_formatter(myFmtlong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QAQC Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Pitch Dependent Magnetic Correction for Heading\n",
    "The pitch of the glider changes by moving the pitch-battery pack. The pitch-battery produces a magnetic field so when it moves, the field moves and this effects our compass data. Having all of the data from a mission loaded in for this correction ensures the best fit possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 135921)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam1amp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: QAQC Pre-Coordinate Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove any bin and bin further away from it that returns an amplitude within 3dB of the noise floor. We also need to calculate the noise floor. This method is recommended by the manual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define noise floor\n",
    "nf = 25 # [dB], reported by Nortek by sampling in air.\n",
    "\n",
    "# SNR_dB = S_dB - N_dB use 13 dB as threshold from Todd 2017\n",
    "snr_threshold = 13\n",
    "\n",
    "# Initialize beam SNRs with NaNs first\n",
    "snr1 = np.empty([beam1amp.shape[0],beam1amp.shape[1]])\n",
    "snr2 = np.empty([beam1amp.shape[0],beam1amp.shape[1]])\n",
    "snr3 = np.empty([beam1amp.shape[0],beam1amp.shape[1]])\n",
    "snr4 = np.empty([beam1amp.shape[0],beam1amp.shape[1]])\n",
    "snr1[:] = np.NaN\n",
    "snr2[:] = np.NaN\n",
    "snr3[:] = np.NaN\n",
    "snr4[:] = np.NaN\n",
    "\n",
    "for i in np.arange(0,beam1amp.shape[1]):\n",
    "    if pitch[i] > 15: # Upcast so use beams 234\n",
    "        # Calculate SNR for each beam\n",
    "        snr2[:,i] = beam2amp[:,i]-nf\n",
    "        snr3[:,i] = beam3amp[:,i]-nf\n",
    "        snr4[:,i] = beam4amp[:,i]-nf\n",
    "        \n",
    "        # If SNR < threshold in a bin in any beam, make that bin nan in all beams needed for this cast\n",
    "        #snr_ind = \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snr2<snr_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Convert from beam to ENU coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
